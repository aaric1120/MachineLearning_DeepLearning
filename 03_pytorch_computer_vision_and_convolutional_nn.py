# -*- coding: utf-8 -*-
"""03_pytorch_computer_vision_and convolutional_nn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15VB8tyDbLmQ4I-jGt06DsHG7FpRWzB_6

### Pytorch Computer Vision and Convolutional NN

Using the library torchvision

## Computer Vision Libraries

* `torchvision`
* `torchvision.datasets` - get datasets and data loading functions
* `torchvision.models` - get pretrained computer vision models
* `torchvision.transfroms` - functions for manipulating your data for ML use
* `torch.utils.data.Dataset` - Base dataset for pytorch
* `torch.utils.data.Dataloader`
"""

# import pytorch
import torch
from torch import nn

# import torchvision
import torchvision
from torchvision import datasets
from torchvision import transforms
from torchvision.transforms import ToTensor

# import matplotlib
import matplotlib.pyplot as plt

# Check versions
print(torch.__version__)
print(torchvision.__version__)

# Device agnostic
device = "cuda" if torch.cuda.is_available() else "cpu"
device

"""### 1. Getting a dataset

The dataset we'll be using `FashionMNIST()`, an updated version of MNIST dataset

IMAGENet is another very popular dataset for training CNN, also available in torchvision
"""

# Getting the training data
train_data = datasets.FashionMNIST(
    root="data", # destination of data
    train=True, # can choose training or testing data
    download=True,
    transform=ToTensor(), # transform the dataset to tensors for NN
    target_transform=None # do you want to transform the label
)

test_data = datasets.FashionMNIST(
    root="data",
    train=False,
    download=True,
    transform=ToTensor(),
    target_transform=None
)

len(train_data), len(test_data)

train_data

train_data.classes

train_data.class_to_idx

type(train_data)

image, label = train_data[0]
image.shape, label

image

"""### Visualize the data

By plotting the data, we can actually see the image
"""

# Plot the very first image
print(f"image shape: {image.shape}")
plt.imshow(image.squeeze(),cmap="gray")
plt.title(label)

# Plot some more
class_names = class_names = train_data.classes
torch.manual_seed(42)
fig=plt.figure(figsize=(9,9))
rows, cols = 4, 4
for i in range(1, rows * cols + 1):
  random_idx = torch.randint(0,len(train_data),size=[1]).item()
  img,label = train_data[random_idx]
  fig.add_subplot(rows,cols,i)
  plt.imshow(img.squeeze(),cmap="gray")
  plt.title(class_names[label])
  plt.axis(False)

"""### Prepare DataLoader

Current data is in Pytorch `Datasets` type, contains tensors??

Dataloader turns the `Dataset` into Python `iterable`

We want to turn our data into batches (or mini-batches)

1. More computationally efficient
2. Escapes local convergence??
3. Gives our nn more chances to update its gradients per epoch (**Mini Batch Gradient Descent**)
"""

# Create the dataloader, feeds data to model in batches for efficiency
from torch.utils.data import DataLoader

# Set the batch size
BATCH_SIZE =  32

# CREATE an instance of dataloader
train_dataloader = DataLoader(
    train_data,
    batch_size=BATCH_SIZE,
    shuffle=True
)

test_dataloader = DataLoader(
    test_data,
    batch_size=BATCH_SIZE,
    shuffle=False
)

print(f"Dataloaders {train_dataloader, test_dataloader}")
print(f"Length of train dataloader: {len(train_dataloader)}")
print(f"Length of test dataloader: {len(test_dataloader)}")

# Check out what's inside the training dataloader
train_features_batch, train_labels_batch = next(iter(train_dataloader))
train_features_batch.shape, train_labels_batch.shape

# Show a sample
torch.manual_seed(42)
random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()
img, label = train_features_batch[random_idx], train_labels_batch[random_idx]
plt.imshow(img.squeeze(), cmap="gray")
plt.title(class_names[label])
plt.axis("Off");
print(f"Image size: {img.shape}")
print(f"Label: {label}, label size: {label.shape}")

"""### Model 0: Build a baseline model

When starting to build a series of machine learning modelling experiments, it's best to start with a baseline model.

A **baseline model** a simpliest model you can to suit your data, then improce upon it
"""

# Create a flatten layer

flatten_model = nn.Flatten()

# get a single sample
x = train_features_batch[0]
x.shape

# Flatten the sample
output = flatten_model(x) # Perform a forward pass

print(f"shape before flattening {x.shape}")
print(f"shape after the flattening {output.shape}") # the data is condensed, doesn't lose number of parameters, but loses a dimension

from torch import nn

class FashionMNISTModelV0(nn.Module):
  def __init__(self,
               input_shape: int,
               hidden_units: int,
               output_shape: int
               ):
    super().__init__()
    self.layer_stack = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features=input_shape,out_features=hidden_units),
        nn.Linear(in_features=hidden_units, out_features=output_shape)
    )

  def forward(self,x):
    return self.layer_stack(x)

# Create an instance with hyperparameters
torch.manual_seed(42)

model_0 = FashionMNISTModelV0(
    input_shape=784,
    hidden_units=10,
    output_shape = len(class_names)
    )

model_0.to("cpu")
model_0

# Create a dummy data
dummy_x = torch.rand([1,1,28,28])
model_0.eval()

with torch.inference_mode():
  output = model_0(dummy_x)

output

"""### Create loss, optimizer and accuracy functions

* Loss Function - Since this is a multiclass classification, we use Cross Entropy
* Optimizer = out optimizer should be SGD
*
"""

import requests
from pathlib import Path

if Path("helper_funcions.py").is_file():
  print("The file you want to download already exists...")
else:
  print("downloading file...")
  request = requests.get("https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py")
  with open("helper_funcions.py","wb") as f:
    f.write(request.content)

# Create the loss and optimizer
from helper_funcions import accuracy_fn

loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model_0.parameters(),
                            lr=0.1)

# Write a timer function to compare device training speed
from timeit import default_timer as timer
def print_train_time(start: float, end: float, device: torch.device = None):
    """Prints difference between start and end time.

    Args:
        start (float): Start time of computation (preferred in timeit format).
        end (float): End time of computation.
        device ([type], optional): Device that compute is running on. Defaults to None.

    Returns:
        float: time between start and end in seconds (higher is longer).
    """
    total_time = end - start
    print(f"Train time on {device}: {total_time:.3f} seconds")
    return total_time

"""### Create the testing and training loop on batches of data

1. Loop through epochs
2. Loop through training batches, perform training steps, calculate train loss per batch
3. Loop through testing batches, perform testing steps, calculate the test loss per patch
4. Print out what's happening
5. time the whole process

"""

# import tqdm
from tqdm.auto import tqdm # This creates a progress bar

# set the random seed
torch.manual_seed(42)
torch.cuda.manual_seed(42)

# start the timer
train_time_start_on_cpu = timer()

# set the epochs
epochs = 3

# Create the training and testing loop
for epoch in tqdm(range(epochs)):
  print(f"Epoch: {epoch}\n--------------")

  # training
  train_loss = 0
  # add a loop through all batches within each epoch
  for batch, (X,y) in enumerate(train_dataloader):
    model_0.train()
    # forward pass
    y_pred = model_0(X)

    # calculate the loss function
    loss = loss_function(y_pred, y)
    train_loss += loss # accumulatively add to loss???

    # optimizer zero grad
    optimizer.zero_grad()

    # backward propagation
    loss.backward()

    # update the parameteres with optimizer (gradient desceent algo)
    optimizer.step()

    # pring out how many samples are left
    if batch % 400 == 0:
      print(f"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples...")

  # divide total train loss by length of train dataloader, gets the average of the batch losses
  train_loss /= len(train_dataloader)

  ### Testing
  # setup variables fro accumulatively adding up loss and accuracy
  test_loss, test_acc = 0,0
  model_0.eval()

  with torch.inference_mode():
    for X, y in test_dataloader:
      # 1. forward pass
      test_pred = model_0(X)

      # calculate the loss
      test_loss += loss_function(test_pred, y)

      # calculate the accuracy
      test_acc += accuracy_fn(y_true=y,
                              y_pred=test_pred.argmax(dim=1))

    # get the average of the accumulative loss and accuracy
    test_loss /= len(test_dataloader)
    test_acc /= len(test_dataloader)

  print(f"\n Train loss: {train_loss:.5f} | Test loss: {test_loss:.5f} | Test Accuracy: {test_acc:.2f}% \n")

# time end
train_time_end_on_cpu = timer()
total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,
                                            end=train_time_end_on_cpu,
                                            device=str(next(model_0.parameters()).device))

# Better understanding of datasets and dataloader outputs
model_0.eval()

with torch.inference_mode():
  y_pred = model_0(next(iter(test_dataloader))[0])

print(next(iter(test_dataloader))[1])
print(y_pred.argmax(dim=1))

# Create a function to automatically evaluate your model
torch.manual_seed(42)
def eval_model(model: torch.nn.Module,
               dataloader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               accuracy_fn,
               device:torch.device = device):
  """
  Returns a dictionary with model results for easier evaluationa
  """
  loss, acc = 0, 0
  model.eval()
  with torch.inference_mode():
    for X,y in tqdm(dataloader):
      X,y = X.to(device),y.to(device)
      model = model.to(device)
      # Make predictions, forward pass
      y_pred = model(X)

      # Accumulate loss and accuary function
      loss += loss_fn(y_pred,y)
      acc += accuracy_fn(y_true=y,
                         y_pred=y_pred.argmax(dim=1))

    # get the average of loss and accuracy per batch
    loss /= len(dataloader)
    acc /= len(dataloader)

    return {
        "model_name": model.__class__.__name__,
        "model_loss": loss.item(), # the item() returns a scalar from tensor??
        "model_acc": acc
    }

"""### Try with Non-Linear model

"""

# setup device agnostic code
import torch
device = "cuda" if torch.cuda.is_available() else "cpu"
device

import torch.nn as nn

# Create non linear class
class FashionMNISTModelV1(nn.Module):
  def __init__(self,
               input_shape: int,
               hidden_units: int,
               output_shape:int):
    super().__init__()
    self.layer_stack = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features=input_shape,out_features=hidden_units),
        nn.ReLU(),
        nn.Linear(in_features=hidden_units,out_features=output_shape),
        nn.ReLU()
    )

  def forward(self,x):
    return self.layer_stack(x)

# Create hyper parameters for model
torch.manual_seed(42)
model_1 = FashionMNISTModelV1(input_shape=784,
                              hidden_units=10,
                              output_shape=len(class_names)).to(device) # don't forget to set to correct device

next(model_1.parameters()).device

from helper_funcions import accuracy_fn
# Create loss and optimizer
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model_1.parameters(),
                            lr=0.1)

# Turn the train and test loop into a function
def train_step(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               optimizer: torch.optim.Optimizer,
               accuracy_fn,
               device: torch.device = device):
  train_loss, train_acc = 0,0
  model.to(device)

  for batch, (X,y) in enumerate(data_loader):
    # Make sure all data is on correct device
    X, y = X.to(device), y.to(device)

    model.train()

    # forward pass
    train_pred = model(X)

    # calculate the loss (accumulative)
    loss = loss_fn(train_pred,y)
    train_loss += loss

    # get the accuracy
    train_acc += accuracy_fn(y_true=y,
                             y_pred=train_pred.argmax(dim=1))

    # optimizer zero grad
    optimizer.zero_grad()

    # Backward propagaion
    loss.backward()

    # optimizer updates the weights based on GD algo
    optimizer.step()

    # get the average of accuracy and
  train_loss /= len(data_loader)
  train_acc /= len(data_loader)

  print(f"Train Loss: {train_loss:.5f} | Train Accuracy: {train_acc:.2f} %")


def test_step(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               accuracy_fn,
               device: torch.device = device):

  test_loss, test_acc = 0,0
  # set model to device
  model.to(device)

  model.eval()
  with torch.inference_mode():
    for X,y in data_loader:
      # send data to gpu
      X, y = X.to(device), y.to(device)

      # Foward pass
      test_pred = model(X)

      # get loss
      test_loss += loss_fn(test_pred, y)

      test_acc += accuracy_fn(y_true=y,
                             y_pred=test_pred.argmax(dim=1))

    # get average of loss and accuracy
    test_loss /= len(data_loader)
    test_acc /= len(data_loader)
  print(f"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\n")

# run the functions above to train non linear model
from timeit import default_timer as timer

torch.manual_seed(42)
torch.cuda.manual_seed(42)

train_time_start_on_gpu = timer()

# set the hyper parameters
epochs = 3

for epoch in tqdm(range(epochs)):
  print(f"Epoch: {epoch}\n------------------")
  train_step(model=model_1,
            data_loader=train_dataloader,
            loss_fn=loss_function,
            accuracy_fn=accuracy_fn,
            optimizer=optimizer
            )

  test_step(model=model_1,
            data_loader=test_dataloader,
            loss_fn=loss_function,
            accuracy_fn=accuracy_fn)

train_time_end_on_gpu = timer()
total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,
                                            end=train_time_end_on_gpu,
                                            device=device)

# Evaluate our model with the eval function we wrote
torch.manual_seed(42)

# Note: This will error due to `eval_model()` not using device agnostic code
model_1_results = eval_model(model=model_1,
    dataloader=test_dataloader,
    loss_fn=loss_function,
    accuracy_fn=accuracy_fn)
model_1_results

# test the eval function
model_0_results = eval_model(model=model_0,
                             dataloader=test_dataloader,
                             loss_fn=loss_function,
                             accuracy_fn=accuracy_fn)

model_0_results

"""### Building a Convolutional Neural Network (CNN)

Input Layer -> Convolutional Layer (algo for image recognition) -> Activation Layer -> Pool Layer (reduce complexity of NN) -> Output Layer
"""

# Create Convolutional NN
import torch
import torch.nn as nn

class FashionMNISTModelV2(nn.Module):
  def __init__(self,
               input_shape: int,
               hidden_units: int,
               output_shape: int):
    super().__init__()
    self.block1 = nn.Sequential(
        nn.Conv2d(in_channels=input_shape, # for convolution layer, the input is the number of color channels
                  out_channels=hidden_units,
                  kernel_size=3, # how big is the square going over the image, kernal(weights)
                  stride=1,
                  padding=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=1),
        nn.ReLU(),
        # the pool layer reduces the number of parameters, but not the shape
        nn.MaxPool2d(kernel_size=2,
                     stride=2) # default stride value is same as kernel
    )
    self.block2 = nn.Sequential(
        nn.Conv2d(hidden_units,hidden_units,3,padding=1),
        nn.ReLU(),
        nn.Conv2d(hidden_units,hidden_units,3,padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2)
    )
    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features=hidden_units*7*7, # each layer within our CNN has compressed our image size,
                                                # when flattened it affects the number of neurons per layer
                                                # Usually you divide the pixel size by (max_pool_layer_kernel_size * 2)
                                                # so 28 / (2*2) = 7 , 7 is your new image width and height, that's where the 7*7 comes from
                  out_features=output_shape)
    )

  def forward(self,x):
    x = self.block1(x)
    x = self.block2(x)
    x = self.classifier(x)
    return x

# Create an instance of the class
torch.manual_seed(42)
model_2 = FashionMNISTModelV2(input_shape=1,
                              hidden_units=32,
                              output_shape=len(class_names)).to(device)

model_2

"""### Stepping through the Convolution Layer"""

# Stepping Through the Convolution Layer
torch.manual_seed(42)

# Create a batch of images
images = torch.rand([32,3,64,64])
test_image = images[0]

images.shape, test_image.shape, test_image

# Create a single conv2d layer

conv_layer = nn.Conv2d(in_channels=3,
                       out_channels = 10, # numberof hidden units
                       kernel_size = 3, # really means a 3x3 square
                       stride=1,
                       padding=0 # used if you want the informatin on the edge of the image
                       )

# pass the data throuhg the conv layer

conv_output = conv_layer(test_image.unsqueeze(dim=0)) # needs a batch number as first dim

conv_output.shape,test_image.shape # the image has been compressed somewhat, the pixel size of the image has gone down

"""### Stepping Through Max Pool"""

# print out original shape of test image
print(f"Original Shape: {test_image.shape}")

# Create Max pool
max_pool_layer = nn.MaxPool2d(
    kernel_size = 2
)

# pass through just the conv layer first
conv_output = conv_layer(test_image.unsqueeze(dim=0))
print(f"Output of Conv layer shape: {conv_output.shape}")

# pass through Max pool layer right after
max_output = max_pool_layer(conv_output) # further reduces the image size, only taking the max value within the kernal(filter)
max_output.shape

torch.manual_seed(42)
# create a random tensor with similar dimnesios
random_tensor = torch.randn([1,1,2,2])
random_tensor

max_pool_layer = nn.MaxPool2d(kernel_size=2)
max_pool_layer(random_tensor).shape # Imagine this as a the operation within a single kernel (filter), meant to heighten features??



"""### Testing and Training the CNN Model"""

# Setup loss and optimizer
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(params=model_2.parameters(),
                             lr=0.1)

torch.manual_seed(42) if device=="cpu" else torch.cuda.manual_seed(42)

# Measure the time
from timeit import default_timer as timer
train_time_start_model_2 = timer()

# Setup Hyperparameters
epochs = 3
for epoch in tqdm(range(epochs)):
  train_step(data_loader=train_dataloader,
             model=model_2,
             loss_fn=loss_function,
             optimizer=optimizer,
             accuracy_fn=accuracy_fn,
             device=device)

  test_step(model=model_2,
            data_loader=test_dataloader,
            loss_fn=loss_function,
            accuracy_fn=accuracy_fn,
            device=device)

# end time
train_time_end_model_2 = timer()
total_train_time_model_2 = print_train_time(start=train_time_start_model_2,
                                            end=train_time_end_model_2,
                                            device=device)

# Get Model 2 Results
model_2_results = eval_model(
    model=model_2,
    dataloader=test_dataloader,
    loss_fn=loss_function,
    accuracy_fn = accuracy_fn,
    device=device
)

model_2_results

device

"""### Compare Results of 3 models"""

import pandas as pd
compare_results = pd.DataFrame([model_0_results,
                                model_1_results,
                                model_2_results])

compare_results

# Add Training time for comparison
compare_results["Training_time"] = [total_train_time_model_0,
                                    total_train_time_model_1,
                                    total_train_time_model_2]

compare_results

# Visualize our model results
compare_results.set_index("model_name")["model_acc"].plot(kind="barh")
plt.xlabel("Accuracy (%)")
plt.ylabel("Model")

compare_results.set_index("model_name")["model_acc"]

"""### Make and Evaluate random predictions with best Model"""

def make_predictions(model:torch.nn.Module,
                     data:list,
                     device: torch.device = device):
  pred_probs = []
  model.to(device)
  model.eval()
  with torch.inference_mode():
    for sample in data:
      # add a batch dimension
      sample = torch.unsqueeze(sample, dim=0).to(device)

      # forward pass
      pred_logits = model(sample)

      # Get prediction probability
      pred_prob = torch.softmax(pred_logits.squeeze(), dim=0)

      # matplotlib uses cpu
      pred_probs.append(pred_prob.cpu())

  # stack the pred-probs to turn list into tensor
  return torch.stack(pred_probs)

import random
# random.seed(42)
test_samples = []
test_labels = []

for sample, label in random.sample(list(test_data), k=9):
  test_samples.append(sample)
  test_labels.append(label)


# view the first sample shape
test_samples[0].shape

plt.imshow(test_samples[0].squeeze(),cmap="gray")
plt.title(class_names[test_labels[0]])

# make predictions
pred_probs = make_predictions(model=model_2,
                              data=test_samples)

# View first 2 predictions probabilities
pred_probs[:2]

# Convert prediction probabilites to labels
pred_classes = pred_probs.argmax(dim=1)
pred_classes

# Plot predictions
plt.figure(figsize=(9,9))
nrows = 3
ncols = 3
for i, sample in enumerate(test_samples):
  # Create the subplot
  plt.subplot(nrows,ncols, i+1)

  # plot the image
  plt.imshow(sample.squeeze(),cmap="gray")

  # find the prediction lavla
  pred_label = class_names[pred_classes[i]]

  # get the truch lable
  truth_label = class_names[test_labels[i]]

  # Create the title text of the plot
  title_text = f"Pred: {pred_label} | Truth: {truth_label}"

  # Check for equality and change the title colour accordingly
  if pred_label == truth_label:
    plt.title(title_text,fontsize=10,c="g")
  else:
    plt.title(title_text,fontsize=10, c="r")

  plt.axis(False)

"""Making a Confusion Matrix for further evaluation

1. Make prediction with trained model
2. Make a confusion Matrix `torchmetrics.ConfusionMatrix`
3. Plot the confusion Matrix using `mlxtend.plotting.plot_confusion_matrix()`
"""

from tqdm.auto import tqdm

# 1. Make predictions
y_preds = []
model_2.eval()

with torch.inference_mode():
  for X, y in tqdm(test_dataloader, desc="Making Predictions"):
    X, y = X.to(device), y.to(device)

    y_logits = model_2(X)

    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)

    y_preds.append(y_pred.cpu())

y_preds_tensor = torch.cat(y_preds)

y_preds_tensor.shape

# Import mlxtend upgraded version
import mlxtend
print(mlxtend.__version__)
assert int(mlxtend.__version__.split(".")[1]) >= 19 # should be version 0.19.0 or higher

# See if torchmetrics exists, if not, install it
try:
    import torchmetrics, mlxtend
    print(f"mlxtend version: {mlxtend.__version__}")
    assert int(mlxtend.__version__.split(".")[1]) >= 19, "mlxtend verison should be 0.19.0 or higher"
except:
    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime
    import torchmetrics, mlxtend
    print(f"mlxtend version: {mlxtend.__version__}")

from torchmetrics import ConfusionMatrix
from mlxtend.plotting import plot_confusion_matrix

# 2. setup confusion matrix instance and compare predictions to targets
confmat = ConfusionMatrix(num_classes=len(class_names),
                          task='multiclass')
confmat_tensor = confmat(preds=y_preds_tensor,
                         target=test_data.targets)

# 3. Plot the confusion Matrix
fig, ax = plot_confusion_matrix(
    conf_mat = confmat_tensor.numpy(),
    class_names=class_names,
    figsize=(10,7)
)

"""### Save and Load Model"""

# Saving the trained parameters to local
from pathlib import Path

# Create the parameters for saving
MODEL_PATH = Path("models")
MODEL_PATH.mkdir(parents=True,
                 exist_ok=True)

# Create model save path
MODEL_NAME = "03_pytorch_computer_vision_model_2.pth"
MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME

# Save the model state dict
print(f"Saving the model to: {MODEL_SAVE_PATH}")
torch.save(obj=model_2.state_dict(),
           f=MODEL_SAVE_PATH)

# Load the data into model
loaded_model_2 = FashionMNISTModelV2(input_shape=1,
                                     hidden_units=32,
                                     output_shape=10)

# Load the data
loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))

loaded_model_2 = loaded_model_2.to(device)

# Try the new loaded data
torch.manual_seed(42)
torch.cuda.manual_seed(42)

loaded_model_2_results = eval_model(
    model=loaded_model_2,
    dataloader=test_dataloader,
    loss_fn = loss_function,
    accuracy_fn=accuracy_fn
)

loaded_model_2_results

model_2_results

# Check if the loaded model results are close to previosu model
torch.isclose(torch.tensor(model_2_results['model_loss']),
              torch.tensor(loaded_model_2_results['model_loss']),
              atol=1e-08, # absolute tolerance
              rtol=0.0001) # relative tolerance/

