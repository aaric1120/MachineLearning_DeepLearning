# -*- coding: utf-8 -*-
"""04_pytorch_custom_datasets.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CpJaBlPrPOX84LTdZKBIjq1CRQTbyVQ9

### Custom Datasets

How to import your own datasets into pytorch and train models with it

## Domain Libraries
Pytorch has pre-built dataloaders for most datatypes, be sure to look into them
"""

import torch
from torch import nn

torch.__version__

# Setup Device agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"
device

import requests
import zipfile
from pathlib import Path

# Setup the data folder
DATA_PATH = Path("data/")
IMAGE_PATH = DATA_PATH / "pizza_steak_sushi"

# Check if these already exist
if IMAGE_PATH.is_dir():
  print(f"image path already exists")
else:
  IMAGE_PATH.mkdir(parents=True,
                   exist_ok=True)

# download the file
with open(DATA_PATH / "pizza_steak_sushi.zip", 'wb') as f: # think the tag 'wb' means write binary for compress files
  request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip")
  print("Downloading pizza, steak, sushi data...")
  f.write(request.content)

# open the file
with zipfile.ZipFile(DATA_PATH / "pizza_steak_sushi.zip", 'r') as zip:
  print("Unzipping the file...")
  zip.extractall(IMAGE_PATH)

"""### Data Preparation and Data Exploration"""

# Walk through each directory
import os

def walk_through_dir(dir_path):
  """
  Walks through the path given and give info about each directory...
  """
  for dirpath, dirnames, filenames in os.walk(dir_path):
    print(f"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath} ")

walk_through_dir(DATA_PATH)

# Setup training and testing data paths
TRAIN_PATH = IMAGE_PATH / "train"
TEST_PATH = IMAGE_PATH / "test"

# Visualize the image
import random
from PIL import Image

# set random seed
random.seed(42)

image_path_list = list(IMAGE_PATH.glob("*/*/*.jpg"))

# get random image
random_image_path = random.choice(image_path_list)

# get image path from list
image_class = random_image_path.parent.stem # gets the parent folder name, in this case the label

# open the img
img = Image.open(random_image_path)

# Print the metadata
# 5. Print metadata
print(f"Random image path: {random_image_path}")
print(f"Image class: {image_class}")
print(f"Image height: {img.height}")
print(f"Image width: {img.width}")
img

# Use numpy instead
import numpy as np
import matplotlib.pyplot as plt

# turn the image into numpy array
img_as_np_array = np.asarray(img)

# plot
plt.figure(figsize=(10,7))
plt.imshow(img_as_np_array)
plt.title(f"Image Class: {image_class} | Image shape: {img_as_np_array.shape} -> [height, width, color channel]")
plt.axis(False)

"""### Transforming the Data into Tensors

Before we can use our image data(or all data) with PyTorch:
1. Turn your data into tensors
2. Turn it into a `torch.utils.data.Dataset` and subsequently a `torch.utils.data.Dataloader`

"""

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# write a transform for an image
data_transform = transforms.Compose([  # Takes a list as input
    # resize the images to 64 x 64
    transforms.Resize(size=(64,64)),
    # Flip the image randomly on the horizontal
    transforms.RandomHorizontalFlip(p=0.5), # probabilyt of 50% of getting flipped to introduce randomness
    # transform the data into tensors
    transforms.ToTensor()
])

data_transform(img).shape

# Visualize the transformed image
def plot_transformed_images(image_paths,transform, n=3, seed=42):
  """
  Plot a series of transformed images from the path
  """
  random.seed(seed)
  random_image_path = random.sample(image_paths, k=n)
  for image_path in random_image_path:
    with Image.open(image_path) as f:
      fig,ax = plt.subplots(1,2)
      ax[0].imshow(f)
      ax[0].set_title(f"Original \nSize: {f.size}")
      ax[0].axis("off")
      # Transform the image
      transformed_image = transform(f).permute(1,2,0) # make the color channel, height, width in correct order for plotting
      ax[1].imshow(transformed_image)
      ax[1].set_title(f"Transformed \nSize: {transformed_image.shape}")
      ax[1].axis("off")

      fig.suptitle(f"Class: {image_path.parent.stem}", fontsize=16)

# plot the image
plot_transformed_images(image_path_list,
                        transform=data_transform,
                        n=3)

"""### Option 1: Loading Image Data using `ImageFolder`

We can load image classification data using `torchvision.datasets.ImageFolder`
"""

# Using ImageFolder to create dataset
from torchvision import datasets
train_data = datasets.ImageFolder(root=TRAIN_PATH,
                                  transform=data_transform,
                                  target_transform=None) # Transform for label??

test_data = datasets.ImageFolder(root=TEST_PATH,
                                 transform=data_transform,
                                 target_transform=None)

print(f"Train Data: \n{train_data} \n Test Data:\n{test_data}")

# Get Class names (Label)
class_names = train_data.classes
class_names

# Get class names in a dict
class_dict = train_data.class_to_idx
class_dict

img, label = train_data[0][0], train_data[0][1]
print(f"Image tensor:\n{img}")
print(f"Image shape: {img.shape}")
print(f"Image datatype: {img.dtype}")
print(f"Image label: {label}")
print(f"Label datatype: {type(label)}")

# Plot the sample
plt.imshow(img.permute(1,2,0))
plt.title(f"Food: {class_names[label]}")
plt.axis(False)

"""### Trun Loaded Image into `Dataloader`

A `Dataloader` is going to help us turn our `Dataset` into batch_size or our model can be more efficient
"""

# turn dataset into dataloader
import os
from torch.utils.data import DataLoader
BATCH_SIZE = 32

train_dataloader = DataLoader(dataset=train_data,
                              batch_size=BATCH_SIZE,
                              num_workers = os.cpu_count(),
                              shuffle=True) # Set Max number of cpu available

test_dataloader = DataLoader(dataset=test_data,
                             batch_size=BATCH_SIZE,
                             num_workers=os.cpu_count(),
                             shuffle=False)

# Check the shape
img, label = next(iter(train_dataloader))

img.shape, label.shape

"""### Option 2: Loading Image Data with Custom Dataset

1. Want to be able to load image from files
2. Want to be able to get class names(Label) from Dataset
3. Want to be able to get class name as dictionary

Pros:
* Can create a `Dataset` for almost everything
* Not limited to pre-built functions

Cons:
* the `Dataset` created may not work with the model
* Requires us to write the code, more possibility for errors

Custom Datasets in PyTorch often subcalss `torch.util.data.Dataset`

"""

# Import all required libraries
import os
import pathlib
import torch
from PIL import Image
from torch.utils.data import Dataset
from torchvision import transforms
from typing import Tuple, Dict, List # What is this ??

"""### Create a helper function to get class names

We want a function to:
1. Get the class names using os.scandir() to traverse target dir and find the `labels`
2. Raise error if dir structure is incorrect
3. Turn the class names into a dict and a list and return them
"""

# Setup path for target directory
TARGET_DIR = TRAIN_PATH
print(TARGET_DIR)

# Get the class Names from the target dir
class_names_found = sorted([entry.name for entry in list(os.scandir(TARGET_DIR))])
class_names_found

def find_classes(input_path):
  """
  finds the directory names in input path
  """
  classes = sorted([entry.name for entry in list(os.scandir(input_path)) if input_path.is_dir()])

  # raise an error if no classes found
  if not classes:
    raise FileNotFoundError(f"could not find directories in input path...")

  # Create a dictionary of the classes
  class_to_idx = {class_name : ind for ind, class_name in enumerate(classes)}
  return classes, class_to_idx

find_classes(TARGET_DIR)

"""### Create a custom `Dataset` to replicate ImageFolder

To create our own dataset:
1. Subclass `torch.util.data.Dataset`
2. Init our subclass with target directory, as well a transform
3. Create several attributes:
  * paths - paths to our image
  * transform
  * classes - a list of label
  * class_to_idx - labels in a dictionary
4. Create a function to load images
5. Overwrite the `__len()__` method
6. Overwrite the `__getitem()__` method to return a given sample when passed an index

"""

# Write a custom dataset Class
from torch.utils.data import Dataset

# 1. Subclass Datasets from torch
class ImageFolderCustom(Dataset):

  # initialize with target path, transform
  def __init__(self, targ_dir, transform=None):
    # Create a list of all jpg paths
    self.paths = list(pathlib.Path(targ_dir).glob("*/*.jpg"))
    # Setup the transform
    self.transform = transform
    # Create class names and class as dict
    self.classes, self.class_to_idx = find_classes(targ_dir)

  # Create a function to load images
  def load_image(self, index):
    image_path = self.paths[index]
    return Image.open(image_path)

  # overwrite the __len()__ function
  def __len__(self):
    return len(self.paths)

  # overwrite __getitem__()
  def __getitem__(self,index):
    """
    Return one sample of data, data and label
    """
    img = self.load_image(index) # Convert image to PIL format
    class_name = self.paths[index].parent.name # Get the label
    class_idx = self.class_to_idx[class_name]

    # Transform the data if transform is given
    if self.transform:
      return self.transform(img), class_idx
    else:
      direct_trans = transforms.Compose([
          transforms.ToTensor()
      ])
      return direct_trans(img), class_idx # why not turn data to tensor even if no transform??

# Create some transforms for the images
train_transforms = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor()
])

test_transforms = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.ToTensor()
])

# Create the datasets from train and test data
train_data_custom = ImageFolderCustom(TRAIN_PATH,train_transforms)

test_data_custom = ImageFolderCustom(TEST_PATH, test_transforms)

train_data_custom, test_data_custom

# how to use the get item function
train_data_custom.__getitem__(6), len(train_data_custom)

# Check for equality amongst our custom Dataset and ImageFolder Dataset
print((len(train_data_custom) == len(train_data)) & (len(test_data_custom) == len(test_data)))
print(train_data_custom.classes == train_data.classes)
print(train_data_custom.class_to_idx == train_data.class_to_idx)

test_test_dataset = ImageFolderCustom(TRAIN_PATH)

test_test_dataset.__getitem__(6)

"""### Create a function to display random images

1. Take a dataset, number of random samples, random seed
"""

def display_random_images(dataset, plt_num, random_seed=None):
  random.seed(random_seed)

  random_ind = random.sample(range(len(dataset)),k=plt_num)

  for plt_ind, img_ind in enumerate(random_ind):
    img, label = dataset.__getitem__(img_ind)
    img = img.permute(1,2,0)

    # plotting the image
    plt.figure(figsize=(16, 8))

    plt.subplot(1, plt_num, plt_ind+1)
    plt.imshow(img)
    plt.title(dataset.classes[label])
    plt.axis(False)

display_random_images(test_data_custom,9)

"""### Load Custom Dataset into Dataloader"""

# Load dataset into Dataloaders
from torch.utils.data import DataLoader
train_dataloader_custom =  DataLoader(dataset=train_data_custom,
                                      batch_size = 32,
                                      num_workers=os.cpu_count(),
                                      shuffle=True)

test_dataloader_custom = DataLoader(dataset=test_data_custom,
                                    batch_size=32,
                                    num_workers=os.cpu_count())

train_dataloader_custom, test_dataloader_custom

# check the output
img_custom ,label_custom = next(iter(train_dataloader_custom))

img_custom.shape, label_custom

"""### Other Forms of Transforms (Data Augmentation)

In the case of image data, this may mean applying various amount of transforms
"""

from torchvision import transforms

train_transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.TrivialAugmentWide(num_magnitude_bins=31), # The intensity of the transforms applied, applies a random number of them??
    transforms.ToTensor()
])

test_transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor()
])

# Get all image paths
plot_transformed_images(
    image_paths=image_path_list,
    transform=train_transform,
    seed=None
)

"""### Model 0: TinyVGG without data augmentation


"""

# Create a simple no augment transform
simple_transform = transforms.Compose({
    transforms.Resize((64,64)),
    transforms.ToTensor()
})

# Load and transform the data
train_data_simple = datasets.ImageFolder(root=TRAIN_PATH,
                                         transform=simple_transform)

test_data_simple = datasets.ImageFolder(root=TEST_PATH,
                                        transform=simple_transform)

# Create the dataloader
train_dataloader_simple = DataLoader(dataset=train_data_simple,
                                     batch_size=32,
                                     shuffle=True)

test_dataloader_simple = DataLoader(dataset=test_data_simple,
                                    batch_size=32)

# Create the model we are gonna use
class TinyVGG(nn.Module):
  def __init__(self,input_shape, hidden_units, output_shape):
    super().__init__()
    self.conv_block1 = nn.Sequential(
        nn.Conv2d(in_channels=input_shape,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=0),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2,
                     stride=2)
    )
    self.conv_block2 = nn.Sequential(
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=0),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2,
                     stride=2)
    )
    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features=hidden_units*13*13,
                  out_features=output_shape,
                  device=device,
                  dtype=torch.float32) # These are still logits, have to be pushed through activation for pred probs,
                                        # then argmax for prob labels

    )
  # the forward function
  def forward(self,x):
    x = self.conv_block1(x)
    x = self.conv_block2(x)
    x = self.classifier(x)
    return x


# Create and instance of the model
torch.cuda.manual_seed(42)
model_0 = TinyVGG(3,10,len(class_names)).to(device)
model_0

# Create loss function and optimizer
loss_function = nn.CrossEntropyLoss()

optimizer = torch.optim.SGD(model_0.parameters(),
                            lr=0.001)

import requests
from pathlib import Path

if Path("helper_funcions.py").is_file():
  print("The file you want to download already exists...")
else:
  print("downloading file...")
  request = requests.get("https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py")
  with open("helper_funcions.py","wb") as f:
    f.write(request.content)

from helper_funcions import accuracy_fn

# get from the bach
simple_train_x, simple_train_y = next(iter(train_dataloader_simple))
simple_train_x[0].shape

model_0.eval()

with torch.inference_mode():
  simple_output = model_0(simple_train_x[0].unsqueeze(dim=0).to(device)) # the input data needs the 'batch' dimension

print(simple_output)
print(torch.softmax(simple_output,dim=1))
print(torch.softmax(simple_output,dim=1).argmax(dim=1))

try:
  import torchinfo
except:
  !pip install torchinfo
  import torchinfo

torchinfo.__version__

from torchinfo import summary

summary(model_0,input_size=[32,3,64,64])

"""### Build the Training and Testing Function"""

# Write the train function
from tqdm import tqdm
def train_step(model:nn.Module,
               dataloader:torch.utils.data.DataLoader,
               loss_fn:torch.nn.Module,
               optimizer:torch.optim.Optimizer,
               accuracy_fn:accuracy_fn,
               device:torch.device=device):
  # set the model into training mode
  model.train()

  # accumulate the loss and accuracy
  train_loss, train_acc = 0, 0


  # Get the data
  for batch, (X, y) in enumerate(dataloader):
    # Make sure the tensors are right device
    X, y = X.to(device), y.to(device)

    # Forward pass
    train_logits = model_0(X)
    train_pred_class = torch.softmax(train_logits, dim=1).argmax(dim=1)

    # Calculate the loss
    loss = loss_fn(train_logits,y)
    train_loss += loss.item()


    # zero the gradient
    optimizer.zero_grad()

    # Backwards propagation
    loss.backward()

    # update the weights and bias with optmized output with GD algorithm
    optimizer.step()

    # Calculate and accumulate accuracy metrics across all batches
    y_pred_class = torch.argmax(torch.softmax(train_logits, dim=1), dim=1)
    train_acc += (y_pred_class == y).sum().item()/len(y_pred_class)

  # Average the loss and accuracy
  train_loss = train_loss / len(dataloader)
  train_acc = train_acc / len(dataloader)
  return train_loss, train_acc

# write the test function
def test_step(model:nn.Module,
              dataloader:torch.utils.data.DataLoader,
              loss_fn:nn.Module,
              accuracy_fn:accuracy_fn,
              device:device=device):

  test_loss, test_acc = 0, 0

  # put the model in eval mode
  model.eval()
  with torch.inference_mode():
    for batch, (X, y) in enumerate(dataloader):
      # Make sure the tensors are right device
      X, y = X.to(device), y.to(device)
      # forward pass
      test_logits = model(X)

      # get the prediction in label form
      test_pred_class = torch.softmax(test_logits, dim=1).argmax(dim=1)

      # calculate the loss
      loss = loss_fn(test_logits, y)
      test_loss += loss.item()

      # Calculate and accumulate accuracy
      test_pred_labels = test_logits.argmax(dim=1)
      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))


    test_loss /= len(dataloader)
    test_acc /= len(dataloader)

  return test_loss, test_acc

"""### Creating a Train() function to combine the train_step and test_step function"""

from tqdm.auto import tqdm

def train(model:nn.Module,
          train_dataloader:torch.utils.data.DataLoader,
          test_dataloader:torch.utils.data.DataLoader,
          optimizer:torch.optim.Optimizer,
          loss_fn:torch.nn.Module = torch.nn.CrossEntropyLoss(),
          accuracy_fn:accuracy_fn=accuracy_fn,
          device:torch.device=device,
          epochs:int = 5):
  # Create empty results dictionary
  results = {
      "train_loss":[],
      "train_acc":[],
      "test_loss":[],
      "test_acc":[]
  }
  for epoch in tqdm(range(epochs)):
    train_loss, train_acc = train_step(model, train_dataloader, loss_fn,optimizer,accuracy_fn,device)

    test_loss, test_acc = test_step(model, test_dataloader, loss_fn,accuracy_fn,device)

    # 4. Print out what's happening
    print(
        f"Epoch: {epoch+1} | "
        f"train_loss: {train_loss:.4f} | "
        f"train_acc: {train_acc:.4f} | "
        f"test_loss: {test_loss:.4f} | "
        f"test_acc: {test_acc:.4f}"
    )

    # 5. Update results dictionary
    # Ensure all data is moved to CPU and converted to float for storage
    results["train_loss"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)
    results["train_acc"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)
    results["test_loss"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)
    results["test_acc"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)

    # 6. Return the filled results at the end of the epochs
  return results

# Start the timer
from timeit import default_timer as timer
start_time = timer()

# Train model_0
model_0_results = train(model=model_0,
                        train_dataloader=train_dataloader_simple,
                        test_dataloader=test_dataloader_simple,
                        optimizer=optimizer,
                        epochs=5)

# End the timer and print out how long it took
end_time = timer()
print(f"Total training time: {end_time-start_time:.3f} seconds")
print(model_0_results)

"""### Plot the Loss Curves of Model 0

A **loss curve** is a way to track your model's progress over time
"""

# Get the model_0 result keys
model_0_results.keys()

def plot_loss_curves(results):
  loss = results['train_loss']
  test_loss = results['test_loss']

  accuracy = results['train_acc']
  test_accuracy = results['test_acc']

  epochs = range(len(results['train_loss']))

  plt.figure(figsize=(15,7))

  # plot loss
  plt.subplot(1,2,1)
  plt.plot(epochs,loss,label='train_loss')
  plt.plot(epochs, test_loss, label='test_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()

  # Plot Accuracy
  plt.subplot(1,2,2)
  plt.plot(epochs, accuracy, label='train_acc')
  plt.plot(epochs,test_accuracy, label="test_acc")
  plt.title('Accurary')
  plt.xlabel('Epochs')
  plt.legend()

plot_loss_curves(model_0_results)

"""### Model 1: TinyVGG with Data Augmentation"""

# Create training transform with Trivial Augment
train_transform_trivial_augment = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.TrivialAugmentWide(num_magnitude_bins=31),
    transforms.ToTensor()
])

test_transform = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.ToTensor()
])

# Create the dataset with new transforms
train_data_augment = datasets.ImageFolder(TRAIN_PATH,
                                          transform=train_transform_trivial_augment
                                          )

test_data_simple = datasets.ImageFolder(TEST_PATH,
                                        transform=test_transform)

train_data_augment, test_data_simple

# Create Dataloaders
import os
BATCH_SIZE = 32
NUM_WORKERS = os.cpu_count()

torch.manual_seed(42)
torch.cuda.manual_seed(42)

train_dataloader_augment = DataLoader(train_data_augment,
                                      batch_size=BATCH_SIZE,
                                      shuffle=True,
                                      num_workers=NUM_WORKERS)

test_dataloader_simple = DataLoader(test_data_simple,
                                    batch_size=BATCH_SIZE,
                                    shuffle=False,
                                    num_workers=NUM_WORKERS)

train_dataloader_augment, test_dataloader_simple

next(iter(train_dataloader_augment))

# Create the model
torch.manual_seed(42)
torch.cuda.manual_seed(42)

model_1 = TinyVGG(input_shape=3,
                  hidden_units=10,
                  output_shape=len(train_data_augment.classes)).to(device)

model_1

# train the new dataset
torch.manual_seed(42)
torch.cuda.manual_seed(42)

# set number of epochs
NUM_EPOCHS = 5

# Setup loss function and optimizer
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params=model_1.parameters(),lr=0.001)

# start the timer
from timeit import default_timer as timer
start_time = timer()

model_1_results = train(model=model_1,
                        train_dataloader=train_dataloader_augment,
                        test_dataloader=test_dataloader_simple,
                        optimizer=optimizer,
                        loss_fn=loss_function,
                        epochs=NUM_EPOCHS)

end_time = timer()

print(f"Total Training Time: {end_time-start_time:.3f} seconds")

plot_loss_curves(model_1_results)

"""### Comparing the Model Results

Ways to do this:
1. Hard Coding
2. Pytorch & Tensorboard
3. Weights & Biases
4. MLFlow
"""

import pandas as pd
model_0_df = pd.DataFrame(model_0_results)
model_1_df = pd.DataFrame(model_1_results)
model_0_df

# Setup a plot
plt.figure(figsize=(15, 10))

# Get number of epochs
epochs = range(len(model_0_df))

# Plot train loss
plt.subplot(2, 2, 1)
plt.plot(epochs, model_0_df["train_loss"], label="Model 0")
plt.plot(epochs, model_1_df["train_loss"], label="Model 1")
plt.title("Train Loss")
plt.xlabel("Epochs")
plt.legend()

# Plot test loss
plt.subplot(2, 2, 2)
plt.plot(epochs, model_0_df["test_loss"], label="Model 0")
plt.plot(epochs, model_1_df["test_loss"], label="Model 1")
plt.title("Test Loss")
plt.xlabel("Epochs")
plt.legend()

# Plot train accuracy
plt.subplot(2, 2, 3)
plt.plot(epochs, model_0_df["train_acc"], label="Model 0")
plt.plot(epochs, model_1_df["train_acc"], label="Model 1")
plt.title("Train Accuracy")
plt.xlabel("Epochs")
plt.legend()

# Plot test accuracy
plt.subplot(2, 2, 4)
plt.plot(epochs, model_0_df["test_acc"], label="Model 0")
plt.plot(epochs, model_1_df["test_acc"], label="Model 1")
plt.title("Test Accuracy")
plt.xlabel("Epochs")
plt.legend();

"""### Make a Prediction on a Custom Image

Although we've trained on custom data, how do you make a prediction on an image that's not in either test or train dataset
"""

# Download custom image
import requests

# setup custom image path
custom_image_path = DATA_PATH / "04-pizza-dad.jpeg"

# download the image if it doesn't exist
if not custom_image_path.is_file():
  with open(custom_image_path,"wb") as f:
    request = requests.get("https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg")
    print(f"Downloading file...")
    f.write(request.content)
else:
  print("Image already exist...")

import torchvision

# read in custom image
custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))

# print out the data
print(f"Custom image tensor:\n{custom_image_uint8}\n") # the dataype of the tensor is wrong
print(f"Custom image shape: {custom_image_uint8.shape}\n")
print(f"Custom image dtype: {custom_image_uint8.dtype}")

# load the image, but with the correct dataype this time
custom_image = torchvision.io.read_image(str(custom_image_path)).type(torch.float32)

# divide the image pixel by 255 to get them between 0 and 1
custom_image = custom_image / 255

# Print out image data
print(f"Custom image tensor:\n{custom_image}\n")
print(f"Custom image shape: {custom_image.shape}\n")
print(f"Custom image dtype: {custom_image.dtype}")

plt.imshow(custom_image.permute(1,2,0))
plt.title(f"Image Shape : {custom_image.shape}")
plt.axis(False)

# Create a custom transform to resize the image
custom_image_transform = transforms.Compose([
    transforms.Resize((64,64))
])

# transfrom the custom image
custom_image_transformed = custom_image_transform(custom_image)

# Print out original shape and new shape
print(f"Original shape: {custom_image.shape}")
print(f"New shape: {custom_image_transformed.shape}")

# run the image tensor through the second model
model_1.eval()

with torch.inference_mode():
  custom_image_logit = model_1.forward(custom_image_transformed.unsqueeze(dim=0).to(device))

custom_image_prob = torch.softmax(custom_image_logit,dim=1)
custom_image_pred = custom_image_prob.argmax(dim=1)

class_names[custom_image_pred]

"""### Putting Everything Above into a Function"""

def pred_and_plot_image(model: torch.nn.Module,
                        image_path: str,
                        class_names: List[str] = None,
                        transform=None,
                        device: torch.device = device):
    """Makes a prediction on a target image and plots the image with its prediction."""

    # 1. Load in image and convert the tensor values to float32
    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)

    # 2. Divide the image pixel values by 255 to get them between [0, 1]
    target_image = target_image / 255.

    # 3. Transform if necessary
    if transform:
        target_image = transform(target_image)

    # 4. Make sure the model is on the target device
    model.to(device)

    # 5. Turn on model evaluation mode and inference mode
    model.eval()
    with torch.inference_mode():
        # Add an extra dimension to the image
        target_image = target_image.unsqueeze(dim=0)

        # Make a prediction on image with an extra dimension and send it to the target device
        target_image_pred = model(target_image.to(device))

    # 6. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)
    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)

    # 7. Convert prediction probabilities -> prediction labels
    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)

    # 8. Plot the image alongside the prediction and prediction probability
    plt.imshow(target_image.squeeze().permute(1, 2, 0)) # make sure it's the right size for matplotlib
    if class_names:
        title = f"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}"
    else:
        title = f"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}"
    plt.title(title)
    plt.axis(False);

# Pred on our custom image
pred_and_plot_image(model=model_1,
                    image_path=custom_image_path,
                    class_names=class_names,
                    transform=custom_image_transform,
                    device=device)